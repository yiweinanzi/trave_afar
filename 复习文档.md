# 总体思路（先结论）

- 用你仓库现成的**端到端链路**当主线：**BGE-M3 语义召回 + RecBole 序列召回 → 候选融合/LLM 重排 → OR-Tools VRPTW 规划（OSMnx时间矩阵） → 文案/标题（DPO）**。仓库 README 已清晰给出架构、指标与文档跳转，复习先照着跑通与复测，然后逐层深挖与做消融。([GitHub](https://github.com/yiweinanzi/trave_afar))
- 每一层都准备三样：**代码走查要点 → 指标与实验再现 → 典型拷打问法与回答证据（含官方文档背书）**。

------

# 复习路线（模块化清单）

## 0）仓库/文档热身（1 次完整复现）

**要做什么**

- 跑 `test_full_pipeline.py`（全链路）与 `app.py`（WebUI），把 README 中的核心数值再现并截图：向量生成（≈1.99s/1333 POI、约600×）、可行率、端到端时延、意图识别等。([GitHub](https://github.com/yiweinanzi/trave_afar))
- 先过一遍仓库里的**文档导航**：`START_HERE.md`、`项目完整文档.md`、`全链路检查报告.md`、`LLM4REC_INTEGRATION.md`、`GPU优化说明.md`（README文末有清单与路径）。([GitHub](https://github.com/yiweinanzi/trave_afar))

**面试证据**

- 复现场景录屏 + 指标面板（你 README 的“性能指标/测试状态”表格作为口径）。([GitHub](https://github.com/yiweinanzi/trave_afar))

------

## 1）语义召回（BGE-M3）

**代码/文档**

- 读 `src/embedding/*` 与你生成向量的脚本；记录**维度、归一化、批大小、TopK**。
- 准备一页“**dense vs dense+lexical（可选）**”的召回曲线与 Query 样例。

**背书资料（挑一句能说出来源）**

- BGE-M3 官方卡：**Multi-Functionality / Multi-Linguality / Multi-Granularity**，最长 **8192 tokens**；多形态检索统一的论断来自模型卡。([Hugging Face](https://huggingface.co/BAAI/bge-m3?utm_source=chatgpt.com))

**常见拷打 & 回法**

- Q：为什么不是 BM25？
   A：口语化/别名/长文本一致性需要 dense；但**可以融合 sparse 分数**做兜底（你有候选融合环节）。引用模型卡的“多形态”特性。([Hugging Face](https://huggingface.co/BAAI/bge-m3?utm_source=chatgpt.com))

------

## 2）序列召回（RecBole · SASRec）

**代码/文档**

- 读 `src/recommendation/*`、`train_recbole_gpu.py`，在 **RecBole** 配一个最小可跑配置（SASRec），确认**切分方式/指标**：Recall@K、NDCG@K、MRR。
- 做一张表：**dense-only / SASRec-only / union** 的 Recall/NDCG 对比。

**背书资料**

- RecBole Quick Start（覆盖通用/序列模型与统一评测接口），官方指标文档里有 **Recall/NDCG/MRR** 定义。([RecBole](https://recbole.io/docs/v1.0.0/get_started/quick_start.html?utm_source=chatgpt.com))

**常见拷打**

- Q：为什么要两路召回？
   A：语义解决表达差异与长文本，序列捕捉**个体偏好迁移**，二者并集去重后更稳，离线看 Recall/NDCG；线上看 CTR/收藏。([RecBole](https://recbole.io/docs/v1.0.0/get_started/quick_start.html?utm_source=chatgpt.com))

------

## 3）候选融合 & LLM 重排

**代码/文档**

- 看 `candidate merge/llm4rec` 相关模块与文档说明：你的 README 里写了**0.7×语义 + 0.3×序列、重排考虑意图匹配/协同性/地理聚合**；做一次**权重 α 敏感性**曲线。([GitHub](https://github.com/yiweinanzi/trave_afar))

**面试点**

- 能说清每个特征的**业务含义**（协同/地理/季节），并给**反例**（权重失衡导致地理“跳点”或季节错配）。

------

## 4）时间矩阵（OSMnx）→ VRPTW（OR-Tools）

**代码/文档**

- 读 `src/routing/*`，确保你知道时间矩阵如何来：**必须先 `add_edge_speeds`，再 `add_edge_travel_times`**（自由流时间）；很多面试官会问“为什么是时间不是距离”。([osmnx.readthedocs.io](https://osmnx.readthedocs.io/en/stable/user-reference.html?utm_source=chatgpt.com))
- 把“硬约束”讲清：营业时间窗/停留时长/日总时长；**Disjunction penalty** 允许跳点；设置搜索策略与时限（避免卡死）。([Google for Developers](https://developers.google.com/optimization/routing/vrptw?utm_source=chatgpt.com))

**背书资料**

- OR-Tools 官方 **VRPTW** 示例（时间维/时间窗/时间矩阵）；**Dimensions** 文档说明“用维度追踪累计时间并施加窗口约束”。([Google for Developers](https://developers.google.com/optimization/routing/vrptw?utm_source=chatgpt.com))
- OSMnx 文档明确 **先加速度再加行程时间**；属于**自由流时间**（非实时交通）。([osmnx.readthedocs.io](https://osmnx.readthedocs.io/en/stable/user-reference.html?utm_source=chatgpt.com))

**常见拷打**

- Q：单车多时间窗为什么有时找不到解/发散？
   A：案例来自社区讨论，**收敛性与搜索空间相关**，要用惩罚、限时、放宽窗或缩小候选。([GitHub](https://github.com/google/or-tools/discussions/3385?utm_source=chatgpt.com))

------

## 5）文案/标题（TRL · DPO）

**代码/文档**

- 看 `content_generation/*` 与你 DPO 训练脚本；准备一个 **(prompt, chosen, rejected)** 的偏好样例与**LoRA/QLoRA**超参。
- 产出一页表：**DPO 前后**的人工可读性评分/CTR 小样本。

**背书资料**

- TRL **DPOTrainer** 官方文档（偏好对、无需显式 RM）。([Hugging Face](https://huggingface.co/docs/trl/en/dpo_trainer?utm_source=chatgpt.com))

**常见拷打**

- Q：DPO 和 PPO 的权衡？
   A：DPO不需要在线采样与显式 RM，低算力好落地；但对偏好数据质量敏感（长度偏好/模板重复需正则化）。([Hugging Face](https://huggingface.co/docs/trl/en/dpo_trainer?utm_source=chatgpt.com))

------

## 6）评测与消融（把“证据链”做成图表）

**你需要准备**

- **召回/排序**：Recall@50、NDCG@10、MRR（dense-only / SASRec-only / union）。([RecBole](https://recbole.io/docs/genindex.html?utm_source=chatgpt.com))
- **规划**：贪心 vs VRPTW 的**可行率/违约束率/总时长**。
- **生成**：DPO 前后主观评分/小流量对比。
- **端到端**：延迟、P95、GPU/CPU对比；README已给到口径，复测并截图。([GitHub](https://github.com/yiweinanzi/trave_afar))

------

## 7）“拷打问法”口袋卡（上场背这几类）

1. **数据与会话层**：过滤/子集/结构化/分类/颗粒度/采样/合成/去重的规则与字段（说得出你表头）；多轮状态如何合并；长上下文如何做检索拼接。
2. **检索/召回/重排**：为什么两路召回、权重如何选、长尾/冷启动怎么兜底（lexical or规则）。([RecBole](https://recbole.io/docs/v1.0.0/get_started/quick_start.html?utm_source=chatgpt.com))
3. **规划**：为什么是 **时间矩阵**；VRPTW 的时间维/窗口/惩罚；**无解策略**。([Google for Developers](https://developers.google.com/optimization/routing/vrptw?utm_source=chatgpt.com))
4. **生成**：为什么 DPO；偏好数据怎么做；过拟合与长度偏好如何抑制。([Hugging Face](https://huggingface.co/docs/trl/en/dpo_trainer?utm_source=chatgpt.com))

------

# 每个模块的“检查清单”（面试当天随手翻）

- **Repo 证据**：README 的**架构图/指标表/文档清单**；一键命令（`test_full_pipeline.py`、`app.py`）。([GitHub](https://github.com/yiweinanzi/trave_afar))
- **官方背书**：
  - BGE-M3 模型卡（多形态与 8192 tokens）。([Hugging Face](https://huggingface.co/BAAI/bge-m3?utm_source=chatgpt.com))
  - RecBole Quick-Start & 指标定义。([RecBole](https://recbole.io/docs/v1.0.0/get_started/quick_start.html?utm_source=chatgpt.com))
  - OR-Tools VRPTW + Dimensions。([Google for Developers](https://developers.google.com/optimization/routing/vrptw?utm_source=chatgpt.com))
  - OSMnx 时间矩阵 API（先速度后时间）。([osmnx.readthedocs.io](https://osmnx.readthedocs.io/en/stable/user-reference.html?utm_source=chatgpt.com))
  - TRL DPOTrainer。([Hugging Face](https://huggingface.co/docs/trl/en/dpo_trainer?utm_source=chatgpt.com))