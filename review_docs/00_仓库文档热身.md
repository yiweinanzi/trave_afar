# 模块0：仓库/文档热身（1次完整复现）

## 📋 目标
- 跑通 `test_full_pipeline.py`（全链路）与 `app.py`（WebUI）
- 把 README 中的核心数值再现并截图
- 过一遍仓库里的文档导航

---

## 🎯 核心指标复现

### 1. 向量生成性能（GPU加速600倍）

**指标要求**：
- CPU: 20分钟处理1333个POI
- GPU (RTX 4090): **1.99秒处理1333个POI** → **600倍加速**
- 速度: **669.7 POI/秒**（GPU）

**复现步骤**：
```bash
# GPU版本（推荐）
python src/embedding/build_embeddings_gpu.py

# 或CPU版本
python -c "from src.embedding.vector_builder import build_poi_embeddings; build_poi_embeddings(use_gpu=False)"
```

**验证点**：
- 检查 `outputs/emb/poi_emb.npy` 是否存在
- 向量维度应为 `(1333, 1024)`（BGE-M3 dense维度）
- 记录实际耗时，对比600倍加速

**面试证据**：
- 截图：GPU版本耗时约1.99秒
- 截图：CPU版本耗时约20分钟
- 计算：加速比 = CPU时间 / GPU时间 ≈ 600x

---

### 2. 语义检索延迟

**指标要求**：
- CPU: <50ms（单次检索）
- GPU: 20ms（单次检索）
- 加速比: 1.75x

**复现步骤**：
```python
from src.embedding.vector_builder import search_similar_pois
import time

query = "想去新疆看雪山和湖泊"
start = time.time()
results = search_similar_pois(query, topk=10, use_gpu=False)
elapsed = (time.time() - start) * 1000  # 毫秒
print(f"CPU延迟: {elapsed:.2f}ms")
```

**验证点**：
- 单次检索延迟 <50ms（CPU）
- 返回Top-K结果正确
- 语义分数在合理范围（0-1）

---

### 3. 端到端推荐性能

**指标要求**：
- CPU: 60分钟（端到端）
- GPU: 10分钟（端到端）
- 加速比: 6x

**复现步骤**：
```bash
# 全链路测试
python test_full_pipeline.py

# 或运行主程序
python main.py
```

**验证点**：
- 完整流程：意图理解 → 召回 → 重排 → 规划 → 生成
- 总耗时在预期范围内
- 生成结果格式正确

---

### 4. 可行率（VRPTW求解）

**指标要求**：
- **可行率: 92%**（VRPTW能找到可行解的比例）

**复现步骤**：
```python
from src.routing.vrptw_solver import VRPTWSolver
from src.routing.time_matrix_builder import build_time_matrix
import pandas as pd

# 加载候选POI
poi_df = pd.read_csv('data/poi.csv').head(20)
time_matrix, poi_df = build_time_matrix(poi_ids=poi_df['poi_id'].tolist())

# 求解
solver = VRPTWSolver(poi_df, time_matrix, start_time_min=480)
solution = solver.solve(
    depot_index=0,
    max_duration_hours=10,
    time_limit_seconds=30
)

if solution:
    print(f"✓ 找到可行解: {solution['visited_pois']}个POI")
else:
    print("✗ 未找到可行解")
```

**验证点**：
- 测试多个场景，统计可行率
- 可行解满足时间窗约束
- 路线总时长不超过限制

---

### 5. 意图识别准确率

**指标要求**：
- **意图识别: 85%+**（LLM模式）

**复现步骤**：
```python
from src.llm4rec.intent_understanding import IntentUnderstandingModule

module = IntentUnderstandingModule(use_template=True)  # 或 use_template=False 使用LLM

test_queries = [
    "想去新疆喀纳斯看3天秋天的景色，拍照",
    "计划去西藏拉萨朝拜布达拉宫，5天深度游",
    "云南大理洱海骑行2天，轻松休闲"
]

for query in test_queries:
    intent = module.understand(query)
    print(f"查询: {query}")
    print(f"省份: {intent.get('province')}")
    print(f"兴趣: {intent.get('interests')}")
    print(f"活动: {intent.get('activities')}")
    print()
```

**验证点**：
- 省份识别准确
- 兴趣点提取正确
- 活动类型匹配

---

## 📚 文档导航清单

### 必读文档（按优先级）

1. **README.md** - 项目总览
   - 架构图
   - 性能指标表
   - 快速开始指南
   - 文档清单

2. **START_HERE.md** - 快速开始指南
   - 环境配置
   - 数据准备
   - 首次运行

3. **项目完整文档.md** - 完整技术文档（2100+行）
   - 技术架构详解
   - 各模块实现细节
   - API文档
   - 性能优化

4. **全链路检查报告.md** - 测试报告
   - 各模块测试结果
   - 性能基准
   - 已知问题

5. **LLM4REC_INTEGRATION.md** - LLM4Rec集成说明
   - 意图理解实现
   - 重排序逻辑
   - LLM调用方式

6. **GPU优化说明.md** - GPU优化方案
   - 向量生成优化
   - 训练加速
   - 显存管理

7. **Web_UI访问指南.md** - Web UI使用
   - Gradio界面说明
   - 公网访问配置

8. **最终交付报告.md** - 项目交付总结
   - 功能清单
   - 性能指标
   - 技术栈

---

## 🔧 一键复现命令

### 全链路测试
```bash
# 1. 环境检查
python test_full_pipeline.py

# 2. 基础功能测试
python test_pipeline.py

# 3. 运行主程序
python main.py

# 4. 启动Web UI
python app.py --port 7860 --share
```

### 性能基准测试
```bash
# GPU向量生成
python src/embedding/build_embeddings_gpu.py --batch-size 128

# 语义检索测试
python -c "
from src.embedding.vector_builder import search_similar_pois
import time
start = time.time()
results = search_similar_pois('想去新疆看雪山', topk=10, use_gpu=True)
print(f'延迟: {(time.time()-start)*1000:.2f}ms')
"

# VRPTW求解测试
python -c "
from src.routing.vrptw_solver import VRPTWSolver
from src.routing.time_matrix_builder import build_time_matrix
import pandas as pd
poi_df = pd.read_csv('data/poi.csv').head(20)
time_matrix, poi_df = build_time_matrix(poi_ids=poi_df['poi_id'].tolist())
solver = VRPTWSolver(poi_df, time_matrix)
solution = solver.solve(max_duration_hours=10)
print(f'可行解: {solution is not None}')
"
```

---

## 📊 面试证据准备

### 1. 性能指标截图
- [ ] GPU向量生成：1.99秒/1333 POI
- [ ] CPU vs GPU对比：600倍加速
- [ ] 语义检索延迟：<50ms
- [ ] 端到端延迟：<30秒
- [ ] VRPTW可行率：92%

### 2. 架构图与流程图
- [ ] 系统架构图（README中的流程图）
- [ ] 数据流图（从查询到结果）
- [ ] 模块依赖关系图

### 3. 测试报告
- [ ] `test_full_pipeline.py` 输出
- [ ] 各模块测试通过截图
- [ ] 性能基准测试结果

### 4. 代码走查要点
- [ ] 主入口：`main.py` 流程清晰
- [ ] 各模块接口：函数签名明确
- [ ] 配置文件：参数可调
- [ ] 错误处理：降级策略

---

## 🎯 面试话术准备

### 开场介绍
> "这是一个完整的端到端旅行路线推荐系统，我实现了从用户查询到路线规划的全流程。核心亮点是GPU加速600倍、多模型协同召回、VRPTW约束规划，以及LLM增强的意图理解和重排序。所有模块都经过全链路测试，可行率达到92%。"

### 技术栈说明
> "项目集成了4个核心库：BGE-M3做语义检索，RecBole做序列推荐，OR-Tools做VRPTW规划，Qwen3做LLM增强。每个模块都有独立的测试和性能基准，可以单独验证效果。"

### 性能数据
> "GPU加速方面，向量生成从20分钟降到1.99秒，加速600倍。端到端推荐从60分钟降到10分钟，加速6倍。语义检索延迟控制在50ms以内，满足实时推荐需求。"

---

## ✅ 检查清单

- [ ] 跑通 `test_full_pipeline.py`，所有测试通过
- [ ] 运行 `app.py`，Web UI正常访问
- [ ] 复现GPU加速600倍（截图保存）
- [ ] 复现语义检索延迟<50ms
- [ ] 复现VRPTW可行率92%
- [ ] 阅读所有核心文档（8篇）
- [ ] 理解系统架构和数据流
- [ ] 准备面试话术和证据材料

---

## 📝 常见问题

**Q: 如何验证GPU加速效果？**
A: 对比CPU和GPU版本的向量生成耗时，计算加速比。GPU版本使用 `build_embeddings_gpu.py`，batch_size=128；CPU版本batch_size=32。

**Q: 全链路测试失败怎么办？**
A: 检查数据文件是否存在（`data/poi.csv`、`data/user_events.csv`），检查向量文件是否生成（`outputs/emb/poi_emb.npy`），检查依赖是否安装完整。

**Q: Web UI无法访问？**
A: 检查端口是否被占用，使用 `--share` 参数获取公网链接，或使用 `--host 0.0.0.0` 允许外部访问。

---

**最后更新**: 2025-01-XX  
**文档版本**: 2.0  
**状态**: ✅ 所有功能已实现  
**对应代码**: `test_full_pipeline.py`, `main.py`, `app.py`

